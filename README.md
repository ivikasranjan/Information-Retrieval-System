# ğŸ“š Information Retrieval System

An **Information Retrieval (IR) System** built with Python that processes documents (PDFs, text) and enables **semantic search & conversational Q&A** using **LangChain, ChromaDB, and Google Gemini API**.  

---

## ğŸš€ Features
- ğŸ“„ Extract text from PDFs  
- âœ‚ï¸ Split documents into chunks for efficient processing  
- ğŸ” Store embeddings in **ChromaDB** (persistent vector database)  
- ğŸ¤– Query documents with **Conversational Retrieval Chain**  
- ğŸ§  Context-aware answers with chat history memory  
- ğŸ”‘ Powered by **Google Gemini (Generative AI)**  

---

## ğŸ› ï¸ Tech Stack
- **Python 3.10+**  
- **LangChain** â€“ framework for LLM apps  
- **Chroma** â€“ vector database  
- **Google Gemini API** â€“ LLM + embeddings  
- **PyPDF2** â€“ PDF text extraction  
- **dotenv** â€“ environment variable management  

---

## ğŸ“‚ Project Structure
Information-Retrieval-System/
â”‚â”€â”€ helper.py # Core logic (PDF reading, embeddings, chain)
â”‚â”€â”€ app.py # Streamlit / CLI app (if applicable)
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ .env # API keys (not committed to GitHub)
â”‚â”€â”€ README.md # Documentation
â”‚â”€â”€ chroma_db/ # Persistent Chroma database
â”‚â”€â”€ sample_pdfs/ # Example PDFs (optional)

yaml
Copy
Edit

---

## âš™ï¸ Installation

1. **Clone the repo**
   ```bash
   git clone https://github.com/<your-username>/Information-Retrieval-System.git
   cd Information-Retrieval-System
Create virtual environment

bash
Copy
Edit
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows
Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
Set up environment variables
Create a .env file in the root folder:

ini
Copy
Edit
GOOGLE_API_KEY=your_google_api_key_here
â–¶ï¸ Usage
Extract Text & Build Vector Store
python
Copy
Edit
from helper import get_pdf_text, get_text_chunks, get_vector_store

pdf_text = get_pdf_text(["sample_pdfs/example.pdf"])
chunks = get_text_chunks(pdf_text)
vector_store = get_vector_store(chunks)
Start Conversational Retrieval
python
Copy
Edit
from helper import get_conversational_chain

chain = get_conversational_chain(vector_store)
response = chain.run("What is this document about?")
print(response)
âš ï¸ Troubleshooting
ResourceExhausted: 429 â†’ You exceeded Gemini API quota.

Use gemini-1.5-flash instead of gemini-1.5-pro.

Add retry with exponential backoff.

Check quota/billing in Google Cloud Console.

ğŸ“Œ Roadmap
 Add support for scanned PDFs (OCR)

 Web UI with Streamlit

 Multi-document retrieval

 Deployment on cloud

ğŸ¤ Contributing
Contributions are welcome!

Fork the repo

Create a feature branch

Submit a pull request

ğŸ“œ License
This project is licensed under the MIT License.

â­ Acknowledgements
LangChain

ChromaDB

Google Gemini API

yaml
Copy
Edit

---

ğŸ‘‰ Do you also want me to create a **requirements.txt** file for this project so your GitHub repo is plug-and-play?






You said:
please give all things in a single cell


ChatGPT said:
Got it ğŸ‘ Hereâ€™s a complete README.md in one single block so you can copy-paste directly into your repo:

markdown
Copy
Edit
# ğŸ“š Information Retrieval System

An **Information Retrieval (IR) System** built with Python that processes documents (PDFs, text) and enables **semantic search & conversational Q&A** using **LangChain, ChromaDB, and Google Gemini API**.  

---

## ğŸš€ Features
- ğŸ“„ Extract text from PDFs  
- âœ‚ï¸ Split documents into chunks for efficient processing  
- ğŸ” Store embeddings in **ChromaDB** (persistent vector database)  
- ğŸ¤– Query documents with **Conversational Retrieval Chain**  
- ğŸ§  Context-aware answers with chat history memory  
- ğŸ”‘ Powered by **Google Gemini (Generative AI)**  

---

## ğŸ› ï¸ Tech Stack
- **Python 3.10+**  
- **LangChain** â€“ framework for LLM apps  
- **Chroma** â€“ vector database  
- **Google Gemini API** â€“ LLM + embeddings  
- **PyPDF2** â€“ PDF text extraction  
- **dotenv** â€“ environment variable management  

---

## ğŸ“‚ Project Structure
Information-Retrieval-System/
â”‚â”€â”€ helper.py # Core logic (PDF reading, embeddings, chain)
â”‚â”€â”€ app.py # Streamlit / CLI app (if applicable)
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ .env # API keys (not committed to GitHub)
â”‚â”€â”€ README.md # Documentation
â”‚â”€â”€ chroma_db/ # Persistent Chroma database
â”‚â”€â”€ sample_pdfs/ # Example PDFs (optional)

yaml
Copy
Edit

---

## âš™ï¸ Installation

1. **Clone the repo**
   ```bash
   git clone https://github.com/<your-username>/Information-Retrieval-System.git
   cd Information-Retrieval-System
Create virtual environment

bash
Copy
Edit
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows
Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
Set up environment variables
Create a .env file in the root folder:

ini
Copy
Edit
GOOGLE_API_KEY=your_google_api_key_here
â–¶ï¸ Usage
Extract Text & Build Vector Store
python
Copy
Edit
from helper import get_pdf_text, get_text_chunks, get_vector_store

pdf_text = get_pdf_text(["sample_pdfs/example.pdf"])
chunks = get_text_chunks(pdf_text)
vector_store = get_vector_store(chunks)
Start Conversational Retrieval
python
Copy
Edit
from helper import get_conversational_chain

chain = get_conversational_chain(vector_store)
response = chain.run("What is this document about?")
print(response)
âš ï¸ Troubleshooting
ResourceExhausted: 429 â†’ You exceeded Gemini API quota.

Use gemini-1.5-flash instead of gemini-1.5-pro.

Add retry with exponential backoff.

Check quota/billing in Google Cloud Console.

ğŸ“Œ Roadmap
 Add support for scanned PDFs (OCR)

 Web UI with Streamlit

 Multi-document retrieval

 Deployment on cloud

ğŸ¤ Contributing
Contributions are welcome!

Fork the repo

Create a feature branch

Submit a pull request

ğŸ“œ License
This project is licensed under the MIT License.

â­ Acknowledgements
LangChain

ChromaDB

Google Gemini API